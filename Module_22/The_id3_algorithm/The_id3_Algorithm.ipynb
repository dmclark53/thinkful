{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The id3 Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'boys': {'short': 2,\n",
    "                      'medium': 6,\n",
    "                      'tall': 4},\n",
    "             'girls': {'short': 5,\n",
    "                       'medium': 2,\n",
    "                       'tall': 1\n",
    "                      }\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(height):\n",
    "    \n",
    "    categories = list(data_dict.keys())\n",
    "    \n",
    "    # Calculate total height\n",
    "    total_height = 0\n",
    "    gender_height = []\n",
    "    for cat in categories:\n",
    "        total_height += data_dict[cat][height]\n",
    "        gender_height.append(data_dict[cat][height])\n",
    "\n",
    "    # Calculate probabilities\n",
    "    probs_height = np.array(gender_height) / total_height\n",
    "\n",
    "    # Calculate inverse probabilities\n",
    "    inverse_probs_height = 1 / probs_height\n",
    "\n",
    "    # Calculate log2 of inverse probabilities\n",
    "    log2_probs_height = np.log2(inverse_probs_height)\n",
    "\n",
    "    # Calculate entropy\n",
    "    h_height = np.dot(probs_height, log2_probs_height)\n",
    "    \n",
    "    # Calculate total not height\n",
    "    total_not_height = 0\n",
    "    gender_not_height = []\n",
    "    store_height = 0\n",
    "    for cat in categories:\n",
    "        for key, value in data_dict[cat].items():\n",
    "            if key != height:\n",
    "                total_not_height += value\n",
    "                store_height += value\n",
    "        gender_not_height.append(store_height)\n",
    "        store_height = 0\n",
    "\n",
    "    # Calculate probabilities\n",
    "    probs_not_height = np.array(gender_not_height) / total_not_height\n",
    "\n",
    "    # Calculate inverse probabilities\n",
    "    inverse_probs_not_height = 1 / probs_not_height\n",
    "\n",
    "    # Calculate log2 of inverse probabilities\n",
    "    log2_probs_not_height = np.log2(inverse_probs_not_height)\n",
    "\n",
    "    # Calculate entropy\n",
    "    h_not_height = np.dot(probs_not_height, log2_probs_not_height)\n",
    "    \n",
    "    # Calculate total\n",
    "    total = 0\n",
    "    for cat in categories:\n",
    "        total += np.sum(list(data_dict[cat].values()))\n",
    "\n",
    "    probs = np.array([total_height, total_not_height]) / total\n",
    "    h_values = np.array([h_height, h_not_height])\n",
    "\n",
    "    h = np.dot(probs, h_values)\n",
    "    print(f'The entropy for {height} is {h:0.3f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy for short is 0.809.\n",
      "The entropy for medium is 0.925.\n",
      "The entropy for tall is 0.928.\n"
     ]
    }
   ],
   "source": [
    "calculate_entropy('short')\n",
    "calculate_entropy('medium')\n",
    "calculate_entropy('tall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drill\n",
    "Match pseudo code with decision tree algorithm from [here](https://github.com/NinjaSteph/DecisionTree/blob/master/sna2111_DecisionTree/DecisionTree.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pseudo Code\n",
    "\n",
    "<pre>\n",
    "Algorithm(Observations, Outcome, Attributes)\n",
    "    Create a root node.\n",
    "    If all observations are 'A', label root node 'A' and return.\n",
    "    If all observations are 'B', label root node 'B' and return.\n",
    "    If no attributes return the root note labeled with the most common Outcome.\n",
    "    Otherwise, start:\n",
    "        For each value v<sub>i</sub> of each attribute a<sub>i</sub>, calculate the entropy.\n",
    "        The attribute a<sub>i</sub> and value v<sub>i</sub> with the lowest entropy is the best rule.\n",
    "        The attribute for this node is then a<sub>i</sub>\n",
    "            Split the tree to below based on the rule a<sub>i</sub> = v<sub>i</sub>\n",
    "            Observations<sub>v<sub>i</sub></sub> is the subset of observations with value v<sub>i</sub>\n",
    "            If Observations<sub>v<sub>i</sub></sub> is empty cap with node labeled with most common Outcome\n",
    "            Else at the new node start a subtree (Observations<sub>v<sub>i</sub></sub>, Target Outcome, Attributes - {a<sub>i</sub>}) and repeat the algorithm\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def makeTree(data, attributes, target, recursion):\n",
    "    recursion += 1\n",
    "    #Returns a new decision tree based on the examples given.\n",
    "    data = data[:]\n",
    "    vals = [record[attributes.index(target)] for record in data]\n",
    "    default = majority(attributes, data, target)\n",
    "\n",
    "\n",
    "    # If the dataset is empty or the attributes list is empty, return the\n",
    "    # default value. When checking the attributes list for emptiness, we\n",
    "    # need to subtract 1 to account for the target attribute.\n",
    "    \n",
    "```\n",
    "\n",
    "<pre>\n",
    "If no attributes return the root note labeled with the most common Outcome.\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "    \n",
    "    if not data or (len(attributes) - 1) <= 0:\n",
    "        return default\n",
    "```\n",
    "\n",
    "<pre>\n",
    "If all observations are 'A', label root node 'A' and return.\n",
    "If all observations are 'B', label root node 'B' and return.\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "    # If all the records in the dataset have the same classification,\n",
    "    # return that classification.\n",
    "    elif vals.count(vals[0]) == len(vals):\n",
    "        return vals[0]\n",
    "    else:\n",
    "        \n",
    "```\n",
    "\n",
    "<pre>\n",
    "If no attributes return the root note labeled with the most common Outcome.\n",
    "\n",
    "Otherwise, start:\n",
    "    For each value v<sub>i</sub> of each attribute a<sub>i</sub>, calculate the entropy.\n",
    "    The attribute a<sub>i</sub> and value v<sub>i</sub> with the lowest entropy is the best rule.\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "        # Choose the next best attribute to best classify our data\n",
    "        best = chooseAttr(data, attributes, target)\n",
    "        # Create a new decision tree/node with the best attribute and an empty\n",
    "        # dictionary object--we'll fill that up next.\n",
    "        tree = {best:{}}\n",
    "    \n",
    "        # Create a new decision tree/sub-node for each of the values in the\n",
    "        # best attribute field\n",
    "```\n",
    "\n",
    "<pre>\n",
    "The attribute for this node is then a<sub>i</sub>\n",
    "    Split the tree to below based on the rule a<sub>i</sub> = v<sub>i</sub>\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "        for val in getValues(data, attributes, best):\n",
    "            # Create a subtree for the current value under the \"best\" field\n",
    "            examples = getExamples(data, attributes, best, val)\n",
    "            newAttr = attributes[:]\n",
    "            \n",
    "```\n",
    "\n",
    "<pre>\n",
    "Observations<sub>v<sub>i</sub></sub> is the subset of observations with value v<sub>i</sub>\n",
    "If Observations<sub>v<sub>i</sub></sub> is empty cap with node labeled with most common Outcome.\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "            newAttr.remove(best)\n",
    "            \n",
    "```\n",
    "\n",
    "<pre>\n",
    "Else at the new node start a subtree (Observations<sub>v<sub>i</sub></sub>, Target Outcome, Attributes - {a<sub>i</sub>}) and repeat the algorithm\n",
    "</pre>\n",
    "\n",
    "```python\n",
    "            subtree = makeTree(examples, newAttr, target, recursion)\n",
    "    \n",
    "            # Add the new subtree to the empty dictionary object in our new\n",
    "            # tree/node we just created.\n",
    "            tree[best][val] = subtree\n",
    "    \n",
    "    return tree\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
