{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Freight Value in the US - Data Cleaning\n",
    "In this project, I will investigate what factors affect the freight value for freight that is transported within the United States. I have taken a dataset from the [Bureau of Transportation Statistics](https://www.bts.gov), which is part of the [US Department of Transportation](https://www.transportation.gov). The dataset will only consider data for the year of 2017. Features in the dataset include: the mode of transportation, the origin and destination, the commodity type, the trade type, the weight, the value, and the distance traveled.\n",
    "\n",
    "In this first notebook, I will clean the dataset to make it suitable for modeling. A second notebook will be dedicated to create the model to answer this project's question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import create_database, database_exists\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import helpers as hp\n",
    "from config import usr, pwd, url, port, db, table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "Load the dataset into a Pandas `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/FAF4.5_2017.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1814034 entries, 0 to 1814033\n",
      "Data columns (total 14 columns):\n",
      "fr_orig        float64\n",
      "dms_orig       int64\n",
      "dms_dest       int64\n",
      "fr_dest        float64\n",
      "fr_inmode      float64\n",
      "dms_mode       int64\n",
      "fr_outmode     float64\n",
      "sctg2          int64\n",
      "trade_type     int64\n",
      "tons_2017      float64\n",
      "value_2017     float64\n",
      "tmiles_2017    float64\n",
      "curval_2017    float64\n",
      "wgt_dist       float64\n",
      "dtypes: float64(9), int64(5)\n",
      "memory usage: 193.8 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Variable Types\n",
    "As seen in the print out above for `df.info()`, all variables are numeric. But, it is clear from the documentation that many of these variables are categorical. To determine which are categorical and which are continuous, I am going to print the number of unique values for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 9 unique values for fr_orig.\n",
      "There are 132 unique values for dms_orig.\n",
      "There are 132 unique values for dms_dest.\n",
      "There are 9 unique values for fr_dest.\n",
      "There are 8 unique values for fr_inmode.\n",
      "There are 8 unique values for dms_mode.\n",
      "There are 8 unique values for fr_outmode.\n",
      "There are 43 unique values for sctg2.\n",
      "There are 3 unique values for trade_type.\n",
      "There are 130082 unique values for tons_2017.\n",
      "There are 205806 unique values for value_2017.\n",
      "There are 112568 unique values for tmiles_2017.\n",
      "There are 206688 unique values for curval_2017.\n",
      "There are 680714 unique values for wgt_dist.\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    print(f'There are {len(df[column].unique())} unique values for {column}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Any variable with less than 140 unique values are categorical variables. All other variables are continuous.\n",
    "\n",
    "I will create two lists to distinguish between continuous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The categorical columns are:\n",
      " ['fr_orig', 'dms_orig', 'dms_dest', 'fr_dest', 'fr_inmode', 'dms_mode', 'fr_outmode', 'sctg2', 'trade_type']\n",
      "The continuous columns are:\n",
      " ['tons_2017', 'value_2017', 'tmiles_2017', 'curval_2017', 'wgt_dist']\n"
     ]
    }
   ],
   "source": [
    "continuous = []\n",
    "categorical = []\n",
    "for column in df.columns:\n",
    "    if len(df[column].unique()) < 140:\n",
    "        categorical.append(column)\n",
    "    else:\n",
    "        continuous.append(column)\n",
    "print(f'The categorical columns are:\\n {categorical}')\n",
    "print(f'The continuous columns are:\\n {continuous}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "Let's deal with missing values for each variable type separately.\n",
    "\n",
    "### Continuous Variables\n",
    "First, I will use a custom function to examine the fraction of missing values for the continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values and their fraction of missing values:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "hp.find_na_columns(df.loc[:, continuous], display_fractions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** There does not appear to be any missing values for this variable type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>tons_2017</td>\n",
       "      <td>1814034.0</td>\n",
       "      <td>9.825770</td>\n",
       "      <td>332.737854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>105266.0771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>value_2017</td>\n",
       "      <td>1814034.0</td>\n",
       "      <td>10.113904</td>\n",
       "      <td>192.679806</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00460</td>\n",
       "      <td>0.05830</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>70962.5892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tmiles_2017</td>\n",
       "      <td>1814034.0</td>\n",
       "      <td>2.802205</td>\n",
       "      <td>95.892118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.00580</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>43088.9030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>curval_2017</td>\n",
       "      <td>1814034.0</td>\n",
       "      <td>9.647496</td>\n",
       "      <td>157.742041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00470</td>\n",
       "      <td>0.05900</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>52077.2198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wgt_dist</td>\n",
       "      <td>1814034.0</td>\n",
       "      <td>1089.400935</td>\n",
       "      <td>879.965088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.03655</td>\n",
       "      <td>888.23455</td>\n",
       "      <td>1535.3388</td>\n",
       "      <td>9970.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count         mean         std  min        25%        50%  \\\n",
       "tons_2017    1814034.0     9.825770  332.737854  0.0    0.00030    0.00750   \n",
       "value_2017   1814034.0    10.113904  192.679806  0.0    0.00460    0.05830   \n",
       "tmiles_2017  1814034.0     2.802205   95.892118  0.0    0.00020    0.00580   \n",
       "curval_2017  1814034.0     9.647496  157.742041  0.0    0.00470    0.05900   \n",
       "wgt_dist     1814034.0  1089.400935  879.965088  0.0  405.03655  888.23455   \n",
       "\n",
       "                   75%          max  \n",
       "tons_2017       0.1362  105266.0771  \n",
       "value_2017      0.8082   70962.5892  \n",
       "tmiles_2017     0.1182   43088.9030  \n",
       "curval_2017     0.8177   52077.2198  \n",
       "wgt_dist     1535.3388    9970.0000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, continuous].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset length is 1814034.\n"
     ]
    }
   ],
   "source": [
    "print(f'The dataset length is {len(df)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Since the dataset length is the same as the value counts for each continuous variable, this is further corroboration that all continuous variables do not contain any missing values.\n",
    "\n",
    "### Categorical Variables\n",
    "Now, I will examine the missing value count for the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values and their fraction of missing values:\n",
      "fr_orig       0.604456\n",
      "fr_dest       0.632710\n",
      "fr_inmode     0.604456\n",
      "fr_outmode    0.632710\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "hp.find_na_columns(df.loc[:, categorical], display_fractions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** A significant number of the categorical variables related to foreign freight have missing values. Let's examine the unique values for each of these variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr_orig: [801. 802. 803. 804. 805. 806. 807. 808.  nan]\n",
      "fr_dest: [801. 802. 803. 804. 805. 806. 807. 808.  nan]\n",
      "fr_inmode: [ 1.  2.  3.  4.  5.  6.  7. nan]\n",
      "fr_outmode: [ 1.  2.  3.  4.  5.  6.  7. nan]\n"
     ]
    }
   ],
   "source": [
    "na_fractions = hp.find_na_columns(df.loc[:, categorical])\n",
    "for column in na_fractions.index.tolist():\n",
    "    print(f'{column}: {np.unique(df[column].unique())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** Origin and destination have the same values. In and out modes have the same values. All missing values are recorded using _nan_. \n",
    "\n",
    "I will fill missing values for the foreign related columns with zeros. Since these are categorical variables, the zeros can indicate that that category is not applicable the shipment for that row. In other words, values with zero for the foreign related columns will indicate that that shipment was only domestic.\n",
    "\n",
    "Before filling missing values, I will copy the raw dataset to a new `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables with missing values and their fraction of missing values:\n",
      "Series([], dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "hp.find_na_columns(df_clean.loc[:, categorical], display_fractions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! I now have dealt with all missing values.\n",
    "\n",
    "## Save Dataset\n",
    "Now, the dataset is clean and can be used for modeling. I will save this cleaned dataset to a SQL database, which I can access during the modeling phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the database if it doesn't exist\n",
    "db_url = f\"postgresql+psycopg2://{usr}:{pwd}@{url}:{port}/{db}\"\n",
    "if database_exists(db_url):\n",
    "    pass\n",
    "else:\n",
    "    create_database(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql+psycopg2://{usr}:{pwd}@{url}:{port}/{db}\")\n",
    "df_clean.to_sql(name=table, con=engine, index=False, if_exists='replace')\n",
    "engine.dispose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
